{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "      <th>joinkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b000jz4hqo</td>\n",
       "      <td>clickart 950 000 - premier image pack (dvd-rom)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>broderbund</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[clickart, 950, 000, premier, image, pack, dvd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b0006zf55o</td>\n",
       "      <td>ca international - arcserve lap/desktop oem 30pk</td>\n",
       "      <td>oem arcserve backup v11.1 win 30u for laptops ...</td>\n",
       "      <td>computer associates</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[ca, international, arcserve, lap, desktop, oe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b00004tkvy</td>\n",
       "      <td>noah's ark activity center (jewel case ages 3-8)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>victory multimedia</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[noah, s, ark, activity, center, jewel, case, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b000g80lqo</td>\n",
       "      <td>peachtree by sage premium accounting for nonpr...</td>\n",
       "      <td>peachtree premium accounting for nonprofits 20...</td>\n",
       "      <td>sage software</td>\n",
       "      <td>599.99</td>\n",
       "      <td>[peachtree, by, sage, premium, accounting, for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b0006se5bq</td>\n",
       "      <td>singing coach unlimited</td>\n",
       "      <td>singing coach unlimited - electronic learning ...</td>\n",
       "      <td>carry-a-tune technologies</td>\n",
       "      <td>99.99</td>\n",
       "      <td>[singing, coach, unlimited, carry, a, tune, te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          id                                              title  \\\n",
       "0           0  b000jz4hqo    clickart 950 000 - premier image pack (dvd-rom)   \n",
       "1           1  b0006zf55o   ca international - arcserve lap/desktop oem 30pk   \n",
       "2           2  b00004tkvy   noah's ark activity center (jewel case ages 3-8)   \n",
       "3           3  b000g80lqo  peachtree by sage premium accounting for nonpr...   \n",
       "4           4  b0006se5bq                            singing coach unlimited   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                NaN   \n",
       "1  oem arcserve backup v11.1 win 30u for laptops ...   \n",
       "2                                                NaN   \n",
       "3  peachtree premium accounting for nonprofits 20...   \n",
       "4  singing coach unlimited - electronic learning ...   \n",
       "\n",
       "                manufacturer   price  \\\n",
       "0                 broderbund    0.00   \n",
       "1        computer associates    0.00   \n",
       "2         victory multimedia    0.00   \n",
       "3              sage software  599.99   \n",
       "4  carry-a-tune technologies   99.99   \n",
       "\n",
       "                                             joinkey  \n",
       "0  [clickart, 950, 000, premier, image, pack, dvd...  \n",
       "1  [ca, international, arcserve, lap, desktop, oe...  \n",
       "2  [noah, s, ark, activity, center, jewel, case, ...  \n",
       "3  [peachtree, by, sage, premium, accounting, for...  \n",
       "4  [singing, coach, unlimited, carry, a, tune, te...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 4397038 pairs in total\n",
      "After Filtering: 743390 pairs left\n",
      "After Verification: 1314 similar pairs\n",
      "(precision, recall, fmeasure) =  (0.4687975646879756, 0.47384615384615386, 0.47130833970925784)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jan 21 16:20:14 2022\n",
    "\n",
    "@author: Elavarasan - ema53\n",
    "\"\"\"\n",
    "# Import Statements\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Class Definition\n",
    "class SimilarityJoin:\n",
    "    def __init__(self, data_file1, data_file2):\n",
    "        self.df1 = pd.read_csv(data_file1)\n",
    "        self.df2 = pd.read_csv(data_file2)\n",
    "\n",
    "    def preprocess_df(self, df, cols):\n",
    "        sliced_df = df[cols].fillna('')\n",
    "        sliced_df['joinkey'] = sliced_df[cols[0]] + ' ' + sliced_df[cols[1]]\n",
    "\n",
    "        def tokenize_keys(join_key):\n",
    "            # Handling non-alpha numeric characters like !, & at the start and end to avoid extra tokens\n",
    "            join_key = re.sub(\"[^0-9a-zA-Z]+\", \" \", join_key)\n",
    "\n",
    "            # Extracting numbers and words from the join key\n",
    "            tokens = re.split(r'\\W+', join_key.strip().lower())\n",
    "            return tokens\n",
    "\n",
    "        df['joinkey'] = sliced_df['joinkey'].apply(tokenize_keys)\n",
    "        return df\n",
    "\n",
    "    def filtering(self, df1, df2):\n",
    "        cols = ['id', 'joinkey']\n",
    "        cols_rename_list = ['id1', 'id2', 'joinkey1', 'joinkey2']\n",
    "\n",
    "        explode_df1 = df1[cols].explode(cols[1]).rename(columns={cols[0]: cols_rename_list[0]})\n",
    "        explode_df2 = df2[cols].explode(cols[1]).rename(columns={cols[0]: cols_rename_list[1]})\n",
    "\n",
    "        # Filtering the matching pairs and removing redundant pairs\n",
    "        joined_df = explode_df1.merge(explode_df2, on=cols[1])\n",
    "        cand_df = joined_df.drop_duplicates(subset=[cols_rename_list[0], cols_rename_list[1]]).drop(cols[1], axis=1)\n",
    "\n",
    "        cand_df = cand_df.merge(df1[cols], left_on=cols_rename_list[0], right_on=cols[0]).drop(cols[0], axis=1) \\\n",
    "            .rename(columns={cols[1]: cols_rename_list[2]})\n",
    "        cand_df = cand_df.merge(df2[cols], left_on=cols_rename_list[1], right_on=cols[0]).drop(cols[0], axis=1) \\\n",
    "            .rename(columns={cols[1]: cols_rename_list[3]})\n",
    "\n",
    "        return cand_df\n",
    "\n",
    "    def verification(self, cand_df, threshold):\n",
    "        columns = ['joinkey1', 'joinkey2']\n",
    "\n",
    "        # Computing Jaccard value for each pair\n",
    "        def compute_jaccard(key1, key2):\n",
    "            intersection_val = len(set(key1).intersection(set(key2)))\n",
    "            union_val = len(set(key1).union(set(key2)))\n",
    "            return intersection_val / union_val\n",
    "\n",
    "        cand_df['jaccard'] = cand_df.apply(lambda row_val: compute_jaccard(row_val[columns[0]], row_val[columns[1]]),\n",
    "                                           axis=1)\n",
    "        result_df = cand_df[cand_df['jaccard'] > threshold]\n",
    "        return result_df\n",
    "\n",
    "    def evaluate(self, result, ground_truth):\n",
    "        result = [tuple(item) for item in result]\n",
    "        ground_truth = [tuple(pair) for pair in ground_truth]\n",
    "\n",
    "        # Finding the true positives - true matching pairs\n",
    "        true_pairs = set(result).intersection(set(ground_truth))\n",
    "\n",
    "        # Calculating the metrics\n",
    "        precision = len(true_pairs) / len(result)\n",
    "        recall = len(true_pairs) / len(ground_truth)\n",
    "        f_measure = (2 * precision * recall) / (precision + recall)\n",
    "        return (precision, recall, f_measure)\n",
    "\n",
    "    def jaccard_join(self, cols1, cols2, threshold):\n",
    "        new_df1 = self.preprocess_df(self.df1, cols1)\n",
    "        new_df2 = self.preprocess_df(self.df2, cols2)\n",
    "\n",
    "        display(new_df1.head())\n",
    "        print(\"Before filtering: %d pairs in total\" % (self.df1.shape[0] * self.df2.shape[0]))\n",
    "\n",
    "        cand_df = self.filtering(new_df1, new_df2)\n",
    "        print(\"After Filtering: %d pairs left\" % (cand_df.shape[0]))\n",
    "\n",
    "        result_df = self.verification(cand_df, threshold)\n",
    "        print(\"After Verification: %d similar pairs\" % (result_df.shape[0]))\n",
    "\n",
    "        return result_df\n",
    "\n",
    "# Main Logic Starts here\n",
    "if __name__ == \"__main__\":\n",
    "    er = SimilarityJoin(\"Amazon.csv\", \"Google.csv\")\n",
    "    amazon_cols = [\"title\", \"manufacturer\"]\n",
    "    google_cols = [\"name\", \"manufacturer\"]\n",
    "    result_df = er.jaccard_join(amazon_cols, google_cols, 0.5)\n",
    "\n",
    "    result = result_df[['id1', 'id2']].values.tolist()\n",
    "    ground_truth = pd.read_csv(\"Amazon_Google_perfectMapping.csv\").values.tolist()\n",
    "    print (\"(precision, recall, fmeasure) = \", er.evaluate(result, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-cuda",
   "language": "python",
   "name": "tf-gpu-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
